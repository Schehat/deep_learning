{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import datasets, layers, models\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "metadata": {
        "id": "h2ebA0iydkle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import data"
      ],
      "metadata": {
        "id": "dT_WcB3vdqzU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\r\n",
        "\r\n",
        "# normalize pixel values to be between 0 and 1\r\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\r\n",
        "\r\n",
        "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\r\n",
        "               \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "outputs": [],
      "metadata": {
        "id": "GU5EvDFSdyWx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Let's look at a one image\r\n",
        "IMG_INDEX = 20\r\n",
        "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\r\n",
        "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "YmKfa5W8eGAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cnn architecture"
      ],
      "metadata": {
        "id": "bk5uMMxker8B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = models.Sequential()\r\n",
        "model.add(layers.Conv2D(32, (3, 3),  # 32 filters & (3, 3) sample size of the filters \r\n",
        "          activation=\"relu\",         # relu on the filters\r\n",
        "          input_shape=(32, 32, 3)))  # image size (32, 32) & 3 dimensions due to rgb\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "# after first layer, the next layers figure out on their own the input_shape\r\n",
        "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\r\n",
        "\r\n",
        "model.summary()\r\n",
        "# number of param: channels_in * kernel_width * kernel_height * channels_out + num_channels\r\n",
        "# first layer: 3*3*3*32+32=896 & second layer: 32*3*3*64+64=18496"
      ],
      "outputs": [],
      "metadata": {
        "id": "R23w3LLGevxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adding dense layer"
      ],
      "metadata": {
        "id": "0_jUs-TJqjcI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.add(layers.Flatten())  # last layer (4, 4, 64) flattened to a vector\r\n",
        "model.add(layers.Dense(64, activation=\"relu\"))  # hidden layer\r\n",
        "model.add(layers.Dense(10))  # output layer\r\n",
        "\r\n",
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "y45Zq-Luql8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training"
      ],
      "metadata": {
        "id": "iOVTSBGuq7jK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "model.compile(optimizer=\"adam\",\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "history = model.fit(train_images, train_labels, epochs=4, validation_data=(test_images, test_labels))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5391 - accuracy: 0.8096 - val_loss: 0.9193 - val_accuracy: 0.7063\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5129 - accuracy: 0.8190 - val_loss: 0.9571 - val_accuracy: 0.7058\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4823 - accuracy: 0.8301 - val_loss: 0.9449 - val_accuracy: 0.7079\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - 63s 41ms/step - loss: 0.4563 - accuracy: 0.8389 - val_loss: 0.9956 - val_accuracy: 0.7161\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37wJcvFwq-R1",
        "outputId": "fc0b3fb1-76ef-4581-de77-1528328ecb39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluate"
      ],
      "metadata": {
        "id": "enzj7wPTubql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\r\n",
        "plt.plot(history.history[\"val_accuracy\"], label = \"val_accuracy\")\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.ylabel(\"Accuracy\")\r\n",
        "plt.ylim([0.5, 1])\r\n",
        "plt.legend(loc=\"lower right\")\r\n",
        "\r\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\r\n",
        "print(test_acc)"
      ],
      "outputs": [],
      "metadata": {
        "id": "gaMh6dJvueUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data augmentation"
      ],
      "metadata": {
        "id": "0n42-M25vmUV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from keras.preprocessing import image\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "# creates a data generator object that transforms images\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "rotation_range=40,\r\n",
        "width_shift_range=0.2,\r\n",
        "height_shift_range=0.2,\r\n",
        "shear_range=0.2,\r\n",
        "zoom_range=0.2,\r\n",
        "horizontal_flip=True,\r\n",
        "fill_mode=\"nearest\")\r\n",
        "\r\n",
        "# pick an image to transform\r\n",
        "test_img = train_images[20]\r\n",
        "img = image.img_to_array(test_img)  # convert image to numpy array\r\n",
        "img = img.reshape((1,) + img.shape)  # reshape image\r\n",
        "\r\n",
        "i = 0\r\n",
        "\r\n",
        "# this loops runs forever until we break, saving images to current directory with specified prefix\r\n",
        "for batch in datagen.flow(img, save_prefix=\"test\", save_format=\"jpeg\"):\r\n",
        "    plt.figure(i)\r\n",
        "    plot = plt.imshow(image.img_to_array(batch[0]))\r\n",
        "    i += 1\r\n",
        "    if i > 4:  # show 4 images\r\n",
        "        break\r\n",
        "\r\n",
        "plt.show()\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "19NAfh58voeK"
      }
    }
  ]
}